<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/assets/main.css">
    <title>Minimalist Blog</title>
  
</head>
<body>
    <header>
        <a href="index.html">&larr; Back</a>
    </header>
    <main style="max-width: 800px; margin: 0 auto; padding: 0 15px;">
    <h1 style="font-size: 2rem;">Half-baked thoughts: On Benchmarks</h1>
    <p>“Why is our model not able to use the right tool for our particular use case, when it is able to solve SAT math questions?”</p>
    <
    <p>While new benchmarks are being reached by models, this does not always translate to gains in business-relevant products and tasks. A couple of issues with these benchmarks:</p>
    
    <ul>
        <li>They're easy to hack.</li>
        <li>They're usually in multiple choice.</li>
    </ul>
    
    <p>With agents, they're either too specified, or does not check for enough.</p>
    
    <p>Think of them as being directionally indicative of reasoning ability, but you need to set up your own evaluations.</p>
    
    <p>For example, if you're working on agents, you need to make sure:</p>
    
    <ol>
        <li>It doesn't perform any unnecessary steps.</li>
        <li>It completes the task successfully.</li>
    </ol>
    
    <p>Of course, AI is definitely getting smarter - but just know, just because models increase in numbers out of the box doesn't mean there will be a lot of prompt tuning and scaffolding to get it to work for your usecase.</p>
</main>
</body>
</html>